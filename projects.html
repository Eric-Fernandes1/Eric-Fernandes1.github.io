<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>All Projects | Eric Fernandes</title>

<style>
    body {
        background-color: #0f172a;
        color: #e2e8f0;
        font-family: Arial, Helvetica, sans-serif;
        margin: 0;
        padding: 0;
        line-height: 1.6;
    }

    header {
        text-align: center;
        padding: 40px;
        background: #1e293b;
    }

    header h1 {
        margin-bottom: 10px;
    }

    .back-btn {
        display: inline-block;
        margin-top: 10px;
        padding: 8px 15px;
        background-color: #38bdf8;
        color: #0f172a;
        border-radius: 5px;
        text-decoration: none;
        font-weight: bold;
    }

    .back-btn:hover {
        background-color: #0ea5e9;
    }

    section {
        max-width: 1000px;
        margin: auto;
        padding: 40px 20px;
    }

    .project {
        background: #1e293b;
        padding: 30px;
        margin-bottom: 50px;
        border-radius: 12px;
    }

    .project h2 {
        text-align: center;
        color: #38bdf8;
        margin-bottom: 15px;
    }

    .subheading {
        margin-top: 20px;
        margin-bottom: 10px;
        text-decoration: underline;
        color: #38bdf8;
        font-size: 18px;
    }

    .media-row {
        display: flex;
        justify-content: center;
        align-items: center;
        gap: 40px;
        margin: 30px 0;
    }

    .media-row img,
    .media-row video {
        width: 500px;
        height: 300px;
        object-fit: cover;
        border-radius: 12px;
    }

    ul {
        margin-left: 20px;
        margin-top: 10px;
        margin-bottom: 15px;
    }

    ul li {
        margin-bottom: 6px;
        color: #cbd5e1;
    }

    footer {
        text-align: center;
        padding: 30px;
        background-color: #1e293b;
        color: #94a3b8;
    }
</style>
</head>

<body>

<header>
    <h1>All Projects</h1>
    <a href="index.html" class="back-btn">← Back to Home</a>
</header>

<section>

    <!-- 6D Pose Estimation Project -->
    <div class="project">
        <h2>6D Pose Estimation System</h2>

        <h3 class="subheading">Challenge</h3>
        <p>
            Enable real-time 6D object pose estimation for variable orientations and 
            integrate it with an ABB manipulator for adaptive pick-and-place 
            without fixed waypoint programming.
        </p>

        <div class="media-row">
            <img src="Aruco Marker Detection .jpg" alt="6D Pose Estimation">
            
            <video controls>
                <source src="Vision_Video.mp4" type="video/mp4">
            </video>
        </div>

        <h3 class="subheading">Technologies & Impact</h3>
        <ul>
            <li>Utilized Intel RealSense RGB-D camera for synchronized real-time 3D perception.</li>
            <li>Implemented YOLO detection with custom PnP solver for accurate 6D pose estimation.</li>
            <li>Performed hand–eye calibration to transform camera coordinates into robot base frame</li>
            <li>Developed Python trajectory generation with ABB RAPID socket-based robot communication.</li>
            <li>Achieved sub-centimeter pose estimation accuracy across repeated operational cycles.</li>
            <li>Eliminated manual robot re-teaching across multiple production cycles</li>
        </ul>
    </div>

    <!-- Project 2 -->
    <div class="project">
        <h2>Intelligent Vision-Guided Sorting Using Dobot MG400</h2>

        <h3 class="subheading">Challenge</h3>
        <p>
            Enable automated classification and sorting of objects based on material 
            type and shape using a robotic manipulator instead of manual sorting.
        </p>

        <div class="media-row">
            <video controls>
                <source src="dobot-port (1).mp4" type="video/mp4">
            </video>
        </div>

        <h3 class="subheading">Technologies & Impact</h3>
        <ul>
            <li>Utilized computer vision for object detection and classification across multiple attributes</li>
            <li>Integrated Dobot MG400 robot using Modbus communication for real-time control.</li>
            <li>Developed control logic supporting operation via Python, Lua, or MATLAB environments.</li>
            <li>Implemented multi-criteria sorting for metal, non-metal, color, and geometric shape categories</li>
            <li>Reduced manual sorting effort and improved repeatability across continuous cycles.</li>
            <li>Created a modular sorting cell adaptable to different industrial classification tasks.</li>
        </ul>
    </div>

    <!-- Project 3 -->
    <div class="project">
        <h2>Multi-Modal Human–Robot Interaction Platform</h2>

        <h3 class="subheading">Challenge</h3>
        <p>
            Enable a humanoid robot to understand spoken commands and perform 
            interactive behaviors through natural language communication.
        </p>

        <div class="media-row">
            <img src="yanshee.mp4" alt="6D Pose Estimation">
            
            <video controls>
                <source src="yanshee-pushups.mp4" type="video/mp4">
            </video>
        </div>

        <h3 class="subheading">Technologies & Impact</h3>
        <ul>
            <li>Integrated custom Raspberry Pi computing unit for onboard processing.</li>
            <li>Implemented speech recognition and NLP for voice command understanding.</li>
            <li>Developed text-to-speech responses for real-time conversational interaction.</li>
            <li>Controlled Yanshee robot actions including walking, dancing, and gestures via APIs.</li>
            <li>Enabled hands-free human–robot interaction without manual control interfaces.</li>
            <li>Created an interactive robotic platform suitable for demonstrations and engagement scenarios.</li>
        </ul>
    </div>

    <!-- Project 4 (ADDED) -->
    <div class="project">
        <h2>Augmented Reality Model-Target Android Application</h2>

        <h3 class="subheading">Challenge</h3>
        <p>
            Develop a mobile AR application capable of recognizing physical objects 
            using model targets and dynamically displaying contextual information 
            to the end user in real time.
        </p>

        <div class="media-row">
            
            <video controls>
                <source src="AR.mp4" type="video/mp4">
            </video>
        </div>

        <h3 class="subheading">Technologies & Impact</h3>
        <ul>
            <li>Developed Android application using Unity Engine for AR-based interaction.</li>
            <li>Integrated Vuforia Engine with Model Target recognition for object tracking.</li>
            <li>Implemented real-time overlay of contextual text on detected physical models.</li>
            <li>Enabled interactive visualization without QR codes or traditional markers.</li>
            <li>Created an intuitive AR experience enhancing user engagement and information accessibility.</li>
        </ul>
    </div>

</section>

<footer>
    © 2026 Eric Fernandes | Robotics Portfolio
</footer>

</body>
</html>
